---
title: "IDS572-Assignment2"
author: "Pritha Ghosh,Anoop Gopalam,Tejaswi Cherukuri"
date: "3/14/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

```{r}
#Initializing all libraries
library(tidyverse)
library(lubridate)
library(ggplot2)
library(dplyr)
library(caret)
library(ROCR)
library(pROC)
```


```{r}
#Load the data
lcdf <- read_csv('lcDataSample5m.csv') #There are total 146 variables
```


```{r}
#Considering only Charged Off and Fully Paid Loans
lcdf <- lcdf %>% filter(loan_status == "Fully Paid" | loan_status == "Charged Off")
 

#converting last payment received date to a date type variable
lcdf$last_pymnt_d<-paste(lcdf$last_pymnt_d, "-01", sep = "")
lcdf$last_pymnt_d<-parse_date_time(lcdf$last_pymnt_d,  "myd")


#computing the duration between the two dates in years
lcdf$actualTerm <- ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dyears(1), 3)


```
```{r}
#Annual Return

#unadjusted annual return
lcdf$annRet <- ((lcdf$total_pymnt-lcdf$funded_amnt)/lcdf$funded_amnt)*(12/36)*100

#actual return
lcdf$actualReturn <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm)*100, 0)

```

```{r}
#derived attributes - Proportion of satisfactory bankcard accounts
lcdf$propSatisBankcardAccts <- ifelse(lcdf$num_bc_tl>0, lcdf$num_bc_sats/lcdf$num_bc_tl, 0)


#derived attribute - length of borrower's history with LC
lcdf$earliest_cr_line<-paste(lcdf$earliest_cr_line, "-01", sep = "")
lcdf$earliest_cr_line<-parse_date_time(lcdf$earliest_cr_line, "myd")
lcdf$borrHistory <- as.duration(lcdf$earliest_cr_line %--% lcdf$issue_d  ) / dyears(1)


#With increase in the duration of borrower history, the rate of default on loans tends to decrease.


#Another new attribute: ratio of openAccounts to totalAccounts
lcdf$PropOpenAcc <- ifelse(lcdf$total_acc>0, lcdf$open_acc/lcdf$total_acc, 0)
grade_PropOpenAcc <- lcdf %>% group_by(grade) %>% summarize(mean(PropOpenAcc))

#With increase in the ratio of open accounts, the rate of default on loans tends to increase.
```
```{r}
#Missing values
#Drop vars with all empty values
lcdf <- lcdf %>% select_if(function(x){!all(is.na(x))})
#Proportions of missing values in each column
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0]
#Remove variables which have more than 60% missing values
nm<-names(lcdf)[colMeans(is.na(lcdf))>0.6]
lcdf <- lcdf %>% select(-nm)


lcdf<- lcdf %>% replace_na(list(mths_since_last_delinq=500, revol_util=median(lcdf$revol_util, na.rm=TRUE), bc_open_to_buy=median(lcdf$bc_open_to_buy, na.rm=TRUE), mo_sin_old_il_acct=1000, mths_since_recent_bc=1000, mths_since_recent_inq=50, num_tl_120dpd_2m = median(lcdf$num_tl_120dpd_2m, na.rm=TRUE),percent_bc_gt_75 = median(lcdf$percent_bc_gt_75, na.rm=TRUE), bc_util=median(lcdf$bc_util, na.rm=TRUE) ))

```

```{r}
#Data leakage

#Dropping these variables that cause data leakage and are not relevant
lcdf <- lcdf %>% select(-c(funded_amnt,funded_amnt_inv,term,emp_title,
                           issue_d,pymnt_plan,title,zip_code,
                           addr_state,delinq_2yrs,inq_last_6mths,
                           mths_since_last_delinq,
                           open_acc,pub_rec,revol_bal,revol_util,total_acc,
                          out_prncp,out_prncp_inv,
                          total_pymnt_inv,total_rec_prncp,total_rec_int,
                       total_rec_late_fee,recoveries,
                       collection_recovery_fee,last_pymnt_d,last_pymnt_amnt,
                       last_credit_pull_d,
                       policy_code,application_type,
                       acc_now_delinq,
                       tot_coll_amt,tot_cur_bal,
                       hardship_flag,
                      disbursement_method,
                       debt_settlement_flag,propSatisBankcardAccts,
                       borrHistory,PropOpenAcc))


lcdf <- lcdf %>% select(-c(X1))
```

```{r}
#Splitting data into train and test sets
set.seed(1234)
library(ROSE)
library(rsample)
lcdfSplit<-initial_split(lcdf, prop=0.7)
lcdfTrn<-training(lcdfSplit)
lcdfTst<-testing(lcdfSplit)
```
#Q1 - We have built 6 different GLM models above , using both Ridge and Lasso Regression and experimented with the different parameter values like alpha, lambda, threshold. We have measured the performance using metrics like AUC, Accuracy, Sensitivity etc. 
#Out of the 6 models, the one built using Lasso with weights is our best model for predicting loan status.We have also examined the variable importance of this model and compared both the performance and variable importance of this model with the other models built in Assignment 1 .
```{r}
#Linear Models
#MODEL 1 - LASSO, WITH LAMDA.MIN

#Linear models - Lasso Model 1 
library(glmnet)
levels(lcdfTrn$loan_status)

#Converting loan status, which is our binary dependent variable to factor
yTrn<-factor(if_else(lcdfTrn$loan_status=="Fully Paid", '1', '0') )
yTst<-factor(if_else(lcdfTst$loan_status=="Fully Paid", '1', '0') )

#Excluding variables we don't want to include in our model
xDTrn<-lcdfTrn %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)
xDTst<-lcdfTst %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)

#Binomial model. This is lasso by default. Alpha = 1
#Run glmnet model to get list of lambda values
glm_ls_m1<- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial")
#Run glmnet model with cv.lasso$lambda.min
GLMmodel1 <- glmnet(xDTrn, yTrn, alpha = 1, family = "binomial",
                lambda = glm_ls_m1$lambda.min)

glm_ls_m1$lambda.min

# Display classification coefficients
coef(GLMmodel1)

# Make predictions on the train data for Model 1
GLM1Trn_prob=predict(glm_ls_m1,data.matrix(xDTrn), s="lambda.min", type="response" )

#predict for trainset Model, 0 stands for Charged Off
GLM1Trn_predclass <- ifelse(GLM1Trn_prob > 0.5, 1, 0)

# Model accuracy
GLM1Trn_obsclass <- lcdfTrn$loan_status
mean(GLM1Trn_predclass == GLM1Trn_obsclass)

#confusion matrix for training
confusionMatrix(as.factor(GLM1Trn_predclass), yTrn)

#ROC for Model 1 train
pred_M1=prediction(GLM1Trn_predclass, yTrn)
roc_M1 <-performance(pred_M1, "tpr", "fpr")
plot(roc_M1) + abline(a=0, b= 1)

#AUC for Model 1 train
aucPref_M1 <-performance(pred_M1, "auc")
aucPref_M1@y.values

# Make predictions on the test data for Model 1
GLM1Tst_prob=predict(glm_ls_m1,data.matrix(xDTst), s="lambda.min", type="response" )

GLM1Tst_predclass <- ifelse(GLM1Tst_prob > 0.5, 1, 0) #Charged off is 0
# Model accuracy
GLM1Tst_obsclass <- lcdfTst$loan_status
mean(GLM1Tst_predclass == GLM1Tst_obsclass)

#confusion matrix
confusionMatrix(as.factor(GLM1Tst_predclass), yTst)
#ROC for Model 1 test
predTst_M1=prediction(GLM1Tst_predclass, yTst)
rocTst_M1 <-performance(predTst_M1, "tpr", "fpr")
plot(rocTst_M1) + abline(a=0, b= 1)

#AUC for Model 1 test
aucPrefTst_M1 <-performance(predTst_M1, "auc")
aucPrefTst_M1@y.values



```

```{r}
#MODEL 2- LASSO WITH LAMDA.1SE
#Binomial model. This is lasso by default. Alpha = 1
#Run glmnet model to get list of lambda values
glm_ls_m2<- cv.glmnet(data.matrix(xDTrn), yTrn, family="binomial")
#Run glmnet model with cv.lasso$lambda.1se
GLMmodel2 <- glmnet(xDTrn, yTrn, alpha = 1, family = "binomial",
                lambda = glm_ls_m2$lambda.1se)

glm_ls_m2$lambda.1se

# Display classification coefficients
coef(GLMmodel2)

# Make predictions on the train data for Model 2
GLM2Trn_prob=predict(glm_ls_m2,data.matrix(xDTrn), s="lambda.1se", type="response" )

#predict for trainset Model, 0 stands for Charged Off
GLM2Trn_predclass <- ifelse(GLM2Trn_prob > 0.5, 1, 0)

# Model accuracy
GLM2Trn_obsclass <- lcdfTrn$loan_status
mean(GLM2Trn_predclass == GLM2Trn_obsclass)

#confusion matrix for training
confusionMatrix(as.factor(GLM2Trn_predclass), yTrn)

#ROC for Model 2 train
pred_M2=prediction(GLM2Trn_predclass, yTrn)
roc_M2<-performance(pred_M2, "tpr", "fpr")
plot(roc_M2) + abline(a=0, b= 1)

#AUC for Model 2 train
aucPref_M2 <-performance(pred_M2, "auc")
aucPref_M2@y.values

# Make predictions on the test data for Model 1
GLM2Tst_prob=predict(glm_ls_m2,data.matrix(xDTst), s="lambda.1se", type="response" )

GLM2Tst_predclass <- ifelse(GLM2Tst_prob > 0.5, 1, 0) #Charged off is 0
# Model accuracy
GLM2Tst_obsclass <- lcdfTst$loan_status
mean(GLM2Tst_predclass == GLM2Tst_obsclass)

#confusion matrix
confusionMatrix(as.factor(GLM2Tst_predclass), yTst)
#ROC for Model 2 test
predTst_M2=prediction(GLM2Tst_predclass, yTst)
rocTst_M2 <-performance(predTst_M2, "tpr", "fpr")
plot(rocTst_M2) + abline(a=0, b= 1)

#AUC for Model 2 test
aucPrefTst_M2 <-performance(predTst_M2, "auc")
aucPrefTst_M2@y.values


```
```{r}
#MODEL 3 - LASSO WITH WEIGHTS,LAMDA.MIN

#Building a glm model with weights
sum(yTrn==0) #number of charged off loans
sum(yTrn==1) #number of fully paid loans
1-sum(yTrn==0)/length(yTrn) #0.85 result
1-sum(yTrn==1)/length(yTrn) #0.14 result

#Using the above calculations as weights
wts=if_else(yTrn==0,1-sum(yTrn==0)/length(yTrn),1-sum(yTrn==1)/length(yTrn))
glm_ls_m3<-cv.glmnet(data.matrix(xDTrn),yTrn,family="binomial",weights=wts)
GLMmodel3 <- glmnet(xDTrn, yTrn, alpha = 1, family = "binomial",
                lambda = glm_ls_m3$lambda.min)
 glm_ls_m3$lambda.min

# Display classification coefficients
coef(GLMmodel3)

# Make predictions on the train data for Model 3
GLM3Trn_prob=predict(glm_ls_m3,data.matrix(xDTrn), s="lambda.min", type="response" )

#predict for trainset Model, 0 stands for Charged Off
GLM3Trn_predclass <- ifelse(GLM3Trn_prob > 0.5, 1, 0)

# Model accuracy
GLM3Trn_obsclass <- lcdfTrn$loan_status
mean(GLM3Trn_predclass == GLM3Trn_obsclass)

#confusion matrix for training
confusionMatrix(as.factor(GLM3Trn_predclass), yTrn)

#ROC for Model 3 train
pred_M3=prediction(GLM3Trn_predclass, yTrn)
roc_M3<-performance(pred_M3, "tpr", "fpr")
plot(roc_M3) + abline(a=0, b= 1)

#AUC for Model 3 train
aucPref_M3 <-performance(pred_M3, "auc")
aucPref_M3@y.values

# Make predictions on the test data for Model 3
GLM3Tst_prob=predict(glm_ls_m3,data.matrix(xDTst), s="lambda.min", type="response" )

GLM3Tst_predclass <- ifelse(GLM3Tst_prob > 0.5, 1, 0) #Charged off is 0
# Model accuracy
GLM3Tst_obsclass <- lcdfTst$loan_status
mean(GLM3Tst_predclass == GLM3Tst_obsclass)

#confusion matrix
confusionMatrix(as.factor(GLM3Tst_predclass), yTst)
#ROC for Model 3 test
predTst_M3=prediction(GLM3Tst_predclass, yTst)
rocTst_M3 <-performance(predTst_M3, "tpr", "fpr")
plot(rocTst_M3) + abline(a=0, b= 1)

#AUC for Model 3 test
aucPrefTst_M3 <-performance(predTst_M3, "auc")
aucPrefTst_M3@y.values

```
```{r}
#MODEL 4 - LASSO WITH OVERSAMPLING, LAMDA.MIN
lcdfTrn_os=ovun.sample(loan_status~.,data=lcdfTrn, method = "over", na.action = na.omit, p=0.5)$data
xDTrn_os<-lcdfTrn_os %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)

yTrn_os<-factor(if_else(lcdfTrn_os$loan_status=="Fully Paid", '1', '0') )

#Binomial model. This is lasso by default. Alpha = 1
#Run glmnet model to get list of lambda values
glm_ls_m4<- cv.glmnet(data.matrix(xDTrn_os), yTrn_os, family="binomial")
#Run glmnet model with cv.lasso$lambda.1se
GLMmodel4 <- glmnet(xDTrn_os, yTrn_os, alpha = 1, family = "binomial",
                lambda = glm_ls_m4$lambda.1se)
glm_ls_m4$lambda.1se

# Display classification coefficients
coef(GLMmodel4)

# Make predictions on the train data for Model 4
GLM4Trn_prob=predict(glm_ls_m4,data.matrix(xDTrn_os), s="lambda.1se", type="response" )

#predict for trainset Model, 0 stands for Charged Off
GLM4Trn_predclass <- ifelse(GLM4Trn_prob > 0.5, 1, 0)

# Model accuracy
GLM4Trn_obsclass <- lcdfTrn_os$loan_status
mean(GLM4Trn_predclass == GLM4Trn_obsclass)

#confusion matrix for training
confusionMatrix(as.factor(GLM4Trn_predclass), yTrn_os)

#ROC for Model 4 train
pred_M4=prediction(GLM4Trn_predclass, yTrn_os)
roc_M4<-performance(pred_M4, "tpr", "fpr")
plot(roc_M4) + abline(a=0, b= 1)

#AUC for Model 4 train
aucPref_M4 <-performance(pred_M4, "auc")
aucPref_M4@y.values

# Make predictions on the test data for Model 4
GLM4Tst_prob=predict(glm_ls_m4,data.matrix(xDTst), s="lambda.1se", type="response" )

GLM4Tst_predclass <- ifelse(GLM4Tst_prob > 0.5, 1, 0) #Charged off is 0
# Model accuracy
GLM4Tst_obsclass <- lcdfTst$loan_status
mean(GLM4Tst_predclass == GLM4Tst_obsclass)

#confusion matrix
confusionMatrix(as.factor(GLM4Tst_predclass), yTst)
#ROC for Model 4 test
predTst_M4=prediction(GLM4Tst_predclass, yTst)
rocTst_M4 <-performance(predTst_M4, "tpr", "fpr")
plot(rocTst_M4) + abline(a=0, b= 1)

#AUC for Model 4 test
aucPrefTst_M4 <-performance(predTst_M4, "auc")
aucPrefTst_M4@y.values




```
```{r}
#MODEL 5 - RIDGE, LAMDA.MIN
m1_ridge <- cv.glmnet(data.matrix(xDTrn), yTrn, alpha = 0, family = "binomial")
GLMmodel5 <- glmnet(xDTrn, yTrn, alpha = 0, family = "binomial",
                lambda = m1_ridge$lambda.min)

m1_ridge$lambda.min

# Display classification coefficients
coef(GLMmodel5)

# Make predictions on the train data for Model 5
GLM5Trn_prob=predict(m1_ridge,data.matrix(xDTrn), s="lambda.min", type="response" )

#predict for trainset Model, 0 stands for Charged Off
GLM5Trn_predclass <- ifelse(GLM5Trn_prob > 0.5, 1, 0)

# Model accuracy
GLM5Trn_obsclass <- lcdfTrn$loan_status
mean(GLM5Trn_predclass == GLM5Trn_obsclass)

#confusion matrix for training
confusionMatrix(as.factor(GLM5Trn_predclass), yTrn)

#ROC for Model 5 train
pred_M5=prediction(GLM5Trn_predclass, yTrn)
roc_M5 <-performance(pred_M5, "tpr", "fpr")
plot(roc_M5) + abline(a=0, b= 1)

#AUC for Model 5 train
aucPref_M5 <-performance(pred_M5, "auc")
aucPref_M5@y.values

# Make predictions on the test data for Model 1
GLM5Tst_prob=predict(m1_ridge,data.matrix(xDTst), s="lambda.min", type="response" )

GLM5Tst_predclass <- ifelse(GLM5Tst_prob > 0.5, 1, 0) #Charged off is 0
# Model accuracy
GLM5Tst_obsclass <- lcdfTst$loan_status
mean(GLM5Tst_predclass == GLM5Tst_obsclass)

#confusion matrix
confusionMatrix(as.factor(GLM5Tst_predclass), yTst)
#ROC for Model 1 test
predTst_M5=prediction(GLM5Tst_predclass, yTst)
rocTst_M5<-performance(predTst_M5, "tpr", "fpr")
plot(rocTst_M5) + abline(a=0, b= 1)

#AUC for Model 1 test
aucPrefTst_M5 <-performance(predTst_M5, "auc")
aucPrefTst_M5@y.values

```
```{r}
#MODEL 6 - RIDGE WITH WEIGHTS, LAMDA.1SE
#Using the above calculations as weights

m2_ridge<-cv.glmnet(data.matrix(xDTrn),yTrn,family="binomial",weights=wts,alpha=0)
GLMmodel6<- glmnet(xDTrn,yTrn, alpha = 0, family = "binomial",
                lambda = m2_ridge$lambda.1se)
m2_ridge$lambda.1se

# Display classification coefficients
coef(GLMmodel6)

# Make predictions on the train data for Model 2
GLM6Trn_prob=predict(m2_ridge,data.matrix(xDTrn), s="lambda.1se", type="response" )

#predict for trainset Model, 0 stands for Charged Off
GLM6Trn_predclass <- ifelse(GLM6Trn_prob > 0.5, 1, 0)

# Model accuracy
GLM6Trn_obsclass <- lcdfTrn$loan_status
mean(GLM6Trn_predclass == GLM6Trn_obsclass)

#confusion matrix for training
confusionMatrix(as.factor(GLM6Trn_predclass), yTrn)

#ROC for Model 1 train
pred_M6=prediction(GLM6Trn_predclass, yTrn)
roc_M6<-performance(pred_M6, "tpr", "fpr")
plot(roc_M6) + abline(a=0, b= 1)

#AUC for Model 1 train
aucPref_M6 <-performance(pred_M6, "auc")
aucPref_M6@y.values

# Make predictions on the test data for Model 1
GLM6Tst_prob=predict(m2_ridge,data.matrix(xDTst), s="lambda.1se", type="response" )

GLM6Tst_predclass <- ifelse(GLM6Tst_prob > 0.5, 1, 0) #Charged off is 0
# Model accuracy
GLM6Tst_obsclass <- lcdfTst$loan_status
mean(GLM6Tst_predclass == GLM6Tst_obsclass)

#confusion matrix
confusionMatrix(as.factor(GLM6Tst_predclass), yTst)
#ROC for Model 1 test
predTst_M6=prediction(GLM6Tst_predclass, yTst)
rocTst_M6<-performance(predTst_M6, "tpr", "fpr")
plot(rocTst_M6) + abline(a=0, b= 1)

#AUC for Model 1 test
aucPrefTst_M6 <-performance(predTst_M6, "auc")
aucPrefTst_M6@y.values
```
#Q2 - We have experimented with 4 GLM models to predict actual returns, using both Ridge and Lasso Regression.We are using Root mean square error as our performance metrics. The model based on Lasso regression and lambda.min is our best performing model.



```{r}
#PREDICTING ACTUAL RETURNS
#splitting the data into training and testing dataset
set.seed(1234)
lcdfSplit<-initial_split(lcdf, prop=0.7)
lcdfTrn<-training(lcdfSplit)
lcdfTst<-testing(lcdfSplit)

#MODEL 1 - GLM RIDGE MODEL
xD<-lcdfTrn %>% select(-loan_status, -actualTerm, -annRet, -actualReturn, -total_pymnt)
glmRet_cv<- cv.glmnet(data.matrix(xD), lcdfTrn$actualReturn,alpha=0, family="gaussian",type.measure="mse")

#Predictions on trainset - with lambda.min
predRetTrn= predict(glmRet_cv, data.matrix(lcdfTrn%>% select(-loan_status, -actualTerm, -annRet, -actualReturn,-total_pymnt)), s="lambda.min" )
sqrt(mean((lcdfTrn$actualReturn- predRetTrn)^2))#Mean square error

#Predictions on testset- with lambda.min
predRetTst= predict(glmRet_cv, data.matrix(lcdfTst%>% select(-loan_status, -actualTerm, -annRet, -actualReturn,-total_pymnt)), s="lambda.min" )
sqrt(mean((lcdfTst$actualReturn- predRetTst)^2)) #mean square error on test set

#Predictions on trainset - with lambda.1se
predRetTrn2= predict(glmRet_cv, data.matrix(lcdfTrn%>% select(-loan_status, -actualTerm, -annRet, -actualReturn,-total_pymnt)), s=glmRet_cv$lambda.1se)
sqrt(mean((lcdfTrn$actualReturn- predRetTrn2)^2))

#Predictions on test set - with lambda.1se
predRetTst2= predict(glmRet_cv, data.matrix(lcdfTst%>% select(-loan_status, -actualTerm, -annRet, -actualReturn,-total_pymnt)), s=glmRet_cv$lambda.1se)
sqrt(mean((lcdfTst$actualReturn- predRetTst2)^2))


```
```{r}
library(glmnet)
#MODEL 2 - GLM LASSO MODEL
xD<-lcdfTrn%>% select(-loan_status, -actualTerm, -annRet, -actualReturn,-total_pymnt)
glmRet_cv<-cv.glmnet(data.matrix(xD), lcdfTrn$actualReturn, type.measure="mse", alpha=1, family="gaussian")

#Predicting on trainset - lambda.min
predRetTrn= predict(glmRet_cv, data.matrix(lcdfTrn%>% select(-loan_status, -actualTerm, -annRet, -actualReturn,-total_pymnt)), s="lambda.min" )
sqrt(mean((lcdfTrn$actualReturn- predRetTrn)^2))

#Predicting on testset - lambda.min
predRetTst= predict(glmRet_cv, data.matrix(lcdfTst%>% select(-loan_status, -actualTerm, -annRet, -actualReturn,-total_pymnt)), s="lambda.min" )
sqrt(mean((lcdfTst$actualReturn- predRetTst)^2))

#Predicting on trainset-lambda.1se
predRetTrn= predict(glmRet_cv, data.matrix(lcdfTrn%>% select(-loan_status, -actualTerm, -annRet, -actualReturn,-total_pymnt)), s="lambda.1se" )
sqrt(mean((lcdfTrn$actualReturn- predRetTrn)^2))

#Predicting on test set - lambda.1se
predRetTst= predict(glmRet_cv, data.matrix(lcdfTst%>% select(-loan_status, -actualTerm, -annRet, -actualReturn,-total_pymnt)), s="lambda.1se" )
sqrt(mean((lcdfTst$actualReturn- predRetTst)^2))

```

#Q2 - We have built 4 RF models using Ranger to predict Actual Returns. We have experimented with different paramters like num.trees,mtry. The RF model with num.trees=200 and mtry=10 is our best model.

```{r}
#RANDOM FOREST MODELS FOR PREDICTING ACTUAL RETURNS
library(ranger)

#Model 1 - 100 trees
rfModel_01<-ranger(actualReturn~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, loan_status)), num.trees=100, importance='permutation')

#Prediction for Model #1
rfPredRet_trn<-predict(rfModel_01, lcdfTrn)
sqrt(mean((rfPredRet_trn$predictions- lcdfTrn$actualReturn)^2))

rfPredRet_tst<-predict(rfModel_01, lcdfTst)
sqrt(mean((rfPredRet_tst$predictions- lcdfTst$actualReturn)^2))

```
```{r}
#Model 2 - 200 trees,mtry=7
rfModel_02<-ranger(actualReturn~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, loan_status)), num.trees=200, importance='permutation',mtry=7)

#Prediction for Model #2
rfPredRet_trn<-predict(rfModel_02, lcdfTrn)
sqrt(mean((rfPredRet_trn$predictions- lcdfTrn$actualReturn)^2))

rfPredRet_tst<-predict(rfModel_02, lcdfTst)
sqrt(mean((rfPredRet_tst$predictions- lcdfTst$actualReturn)^2))

```

```{r}
#Model 3 - 200 trees,mtry=10
rfModel_03<-ranger(actualReturn~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, loan_status)), num.trees=200, importance='permutation',mtry=10)

#Prediction for Model #3
rfPredRet_trn<-predict(rfModel_03, lcdfTrn)
sqrt(mean((rfPredRet_trn$predictions- lcdfTrn$actualReturn)^2))

rfPredRet_tst<-predict(rfModel_03, lcdfTst)
sqrt(mean((rfPredRet_tst$predictions- lcdfTst$actualReturn)^2))

plot ( (predict(rfModel_03, lcdfTst))$predictions, lcdfTst$actualReturn)
plot ( (predict(rfModel_03, lcdfTrn))$predictions, lcdfTrn$actualReturn)
```

```{r}
#Model 4 - 500 trees
rfModel_04<-ranger(actualReturn~., data=subset(lcdfTrn, select=-c(annRet, actualTerm, loan_status)), num.trees=500, importance='permutation')

#Prediction for Model #4
rfPredRet_trn<-predict(rfModel_04, lcdfTrn)
sqrt(mean((rfPredRet_trn$predictions- lcdfTrn$actualReturn)^2))

rfPredRet_tst<-predict(rfModel_04, lcdfTst)
sqrt(mean((rfPredRet_tst$predictions- lcdfTst$actualReturn)^2))


```
#Q2 - We have built GBM models to predict Actual Returns. The parameters that we have experimented with are number of trees, interaction depth, shrinkage, bag function, cross validation folds and number of cores.The GBM model with n.trees=200 is our best model.


```{r}
#GBM model for predicting Actual Returns
library(gbm)
lcdfTrn$grade=as.factor(lcdfTrn$grade)
lcdfTrn$sub_grade=as.factor(lcdfTrn$sub_grade)
lcdfTrn$home_ownership=as.factor(lcdfTrn$home_ownership)
lcdfTrn$verification_status=as.factor(lcdfTrn$verification_status)
lcdfTrn$earliest_cr_line=as.factor(lcdfTrn$earliest_cr_line)
lcdfTrn$emp_length=as.factor(lcdfTrn$emp_length)
lcdfTrn$purpose=as.factor(lcdfTrn$purpose)
lcdfTrn= lcdfTrn %>% mutate_if(is.character, as.factor)

lcdfTst$grade=as.factor(lcdfTst$grade)
lcdfTst$sub_grade=as.factor(lcdfTst$sub_grade)
lcdfTst$home_ownership=as.factor(lcdfTst$home_ownership)
lcdfTst$verification_status=as.factor(lcdfTst$verification_status)
lcdfTst$earliest_cr_line=as.factor(lcdfTst$earliest_cr_line)
lcdfTst$emp_length=as.factor(lcdfTst$emp_length)
lcdfTst$purpose=as.factor(lcdfTst$purpose)
lcdfTst= lcdfTst%>% mutate_if(is.character, as.factor)

gbmModel_01<-gbm(formula=actualReturn~., data=subset(data.frame(lcdfTrn), select=-c(annRet, actualTerm, loan_status)), distribution = 'gaussian', n.trees= 100, interaction.depth= 2, shrinkage = 0.1, bag.fraction= 0.5, cv.folds= 5, n.cores=NULL )

#GBM Model 1 prediction
gbPredRet_trn <- predict(gbmModel_01, lcdfTrn, type = "response")
sqrt(mean((gbPredRet_trn-lcdfTrn$actualReturn)^2))

gbPredRet_tst <- predict(gbmModel_01, lcdfTst, type = "response")
sqrt(mean((gbPredRet_tst-lcdfTst$actualReturn)^2))
```
```{r}
#GBM Model 2 for Actual Returns
gbmModel_02<-gbm(formula=actualReturn~., data=subset(data.frame(lcdfTrn), select=-c(annRet, actualTerm, loan_status)), distribution = 'gaussian', n.trees= 200, interaction.depth= 2, shrinkage = 0.1, bag.fraction= 0.5, cv.folds= 5, n.cores=NULL )

#GBM Model 2 prediction
gbPredRet_trn <- predict(gbmModel_02, lcdfTrn, type = "response")
sqrt(mean((gbPredRet_trn-lcdfTrn$actualReturn)^2))

gbPredRet_tst <- predict(gbmModel_02, lcdfTst, type = "response")
sqrt(mean((gbPredRet_tst-lcdfTst$actualReturn)^2))

plot((predict(gbmModel_02, lcdfTrn)), lcdfTrn$actualReturn)
plot((predict(gbmModel_02, lcdfTst)), lcdfTst$actualReturn)

#decile for predicting returns
#for train set
predRet_Trn<-lcdfTrn%>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(gbPredRet_trn)
predRet_Trn<-predRet_Trn%>% mutate(tile=ntile(-gbPredRet_trn, 10))

a <- predRet_Trn%>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(gbPredRet_trn), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
view(a)

#for test set

predRet_Tst<-lcdfTst%>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(gbPredRet_tst)
predRet_Tst<-predRet_Tst%>% mutate(tile=ntile(-gbPredRet_tst, 10))

b <- predRet_Tst%>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(gbPredRet_tst), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
view(b)

```
#We have experimented with a 50:50 split as well to compare model performance compared to a 70:30 split. The 70:30 split is better.

```{r}
#GBM Model with 50:50 splitting
lcdfSplit<-initial_split(lcdf, prop=0.5)
lcdfTrn0.5 <-training(lcdfSplit)
lcdfTst0.5 <-testing(lcdfSplit)

lcdfTrn0.5$grade=as.factor(lcdfTrn0.5$grade)
lcdfTrn0.5$sub_grade=as.factor(lcdfTrn0.5$sub_grade)
lcdfTrn0.5$home_ownership=as.factor(lcdfTrn0.5$home_ownership)
lcdfTrn0.5$verification_status=as.factor(lcdfTrn0.5$verification_status)
lcdfTrn0.5$earliest_cr_line=as.factor(lcdfTrn0.5$earliest_cr_line)
lcdfTrn0.5$emp_length=as.factor(lcdfTrn0.5$emp_length)
lcdfTrn0.5$purpose=as.factor(lcdfTrn0.5$purpose)
lcdfTrn0.5= lcdfTrn0.5 %>% mutate_if(is.character, as.factor)

lcdfTst0.5$grade=as.factor(lcdfTst0.5 $grade)
lcdfTst0.5$sub_grade=as.factor(lcdfTst0.5 $sub_grade)
lcdfTst0.5 $home_ownership=as.factor(lcdfTst0.5 $home_ownership)
lcdfTst0.5 $verification_status=as.factor(lcdfTst0.5 $verification_status)
lcdfTst0.5 $earliest_cr_line=as.factor(lcdfTst0.5 $earliest_cr_line)
lcdfTst0.5 $emp_length=as.factor(lcdfTst0.5 $emp_length)
lcdfTst0.5 $purpose=as.factor(lcdfTst0.5 $purpose)
lcdfTst0.5 = lcdfTst0.5 %>% mutate_if(is.character, as.factor)

gbmModel_best<-gbm(formula=actualReturn~., data=subset(data.frame(lcdfTrn0.5), select=-c(annRet, actualTerm, loan_status)), distribution = 'gaussian', n.trees= 200, interaction.depth= 2, shrinkage = 0.1, bag.fraction= 0.5, cv.folds= 5, n.cores=NULL )

#GBM Model 2 prediction
gbPredRet_trn <- predict(gbmModel_best, lcdfTrn0.5, type = "response")
sqrt(mean((gbPredRet_trn-lcdfTrn0.5$actualReturn)^2))

gbPredRet_tst <- predict(gbmModel_best, lcdfTst0.5, type = "response")
sqrt(mean((gbPredRet_tst-lcdfTst0.5$actualReturn)^2))

#GBM Model 2 Plot for training and testing data

plot((predict(gbmModel_best, lcdfTrn0.5)), lcdfTrn0.5$actualReturn)
plot((predict(gbmModel_best, lcdfTst0.5)), lcdfTst0.5$actualReturn)

```
#Q2 - We developed XG Boost models to predict Actual Returns. The performance of XGBoost is the best among all the methods that we have tried.

#Q3-We also developed decile charts on this model to see which loans would be a good investment. After analyzing the test data decile chart, we would recommend investing in the loans in the top 3 deciles since it has a good average rate of return.There are total 7293 loans in the top 3 deciles, out of which 339 are charged off and 6954 are fully paid. Most of the loans in the top 3 deciles are distributed across Grade C and Grade D. Therefore, we would choose to invest in the loans of Grade C or Grade D.


```{r}
#XGBoost Model for Actual Returns - Model 1 
view(lcdfTrn)
library(xgboost)
library(caret)

train_x = data.matrix(lcdfTrn[, -55])
train_y = lcdfTrn[,55]

test_x = data.matrix(lcdfTst[, -55])
test_y = lcdfTst[, 55]

xgb_train = xgb.DMatrix(data =subset(train_x,select=-c(annRet, actualTerm, loan_status)),label = as.matrix(train_y))
xgb_test = xgb.DMatrix(data = subset(test_x,select=-c(annRet, actualTerm, loan_status)), label = as.matrix(test_y))

xgbc = xgboost(data=xgb_train, max.depth = 5, nrounds = 500)

pred_train = predict(xgbc, xgb_train)
sqrt(mean((pred_train-lcdfTrn$actualReturn)^2))
pred_y = predict(xgbc, xgb_test)
sqrt(mean((pred_y-lcdfTst$actualReturn)^2))

plot((predict(xgbc,xgb_train)), lcdfTrn$actualReturn)
plot((predict(xgbc,xgb_test)), lcdfTst$actualReturn)


#decile 
predRet_Trn<-lcdfTrn%>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(pred_train)
predRet_Trn<-predRet_Trn%>% mutate(tile=ntile(-pred_train, 10))

a <- predRet_Trn%>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(pred_train), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
view(a)

#for test set

predRet_Tst<-lcdfTst%>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>% mutate(pred_y)
predRet_Tst<-predRet_Tst%>% mutate(tile=ntile(-pred_y, 10))

b <- predRet_Tst%>% group_by(tile) %>%  summarise(count=n(), avgpredRet=mean(pred_y), numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn), maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
view(b)



```

```{r}
#XGBoost Model 2 for Predicting Actual Returns - commenting out now since the above model is best and is being used in further calculatons for next ques.
xgb_train_02 = xgb.DMatrix(data =subset(train_x,select=-c(annRet, actualTerm, loan_status)),label = as.matrix(train_y))
xgb_test_02 = xgb.DMatrix(data = subset(test_x,select=-c(annRet, actualTerm, loan_status)), label = as.matrix(test_y))

xgbc_02 = xgboost(data=xgb_train_02, max.depth = 10, nrounds = 500)

pred_train_02 = predict(xgbc_02, xgb_train_02)
sqrt(mean((pred_train_02-lcdfTrn$actualReturn)^2))
pred_y_02 = predict(xgbc_02, xgb_test_02)
sqrt(mean((pred_y_02-lcdfTst$actualReturn)^2))
```
#We tried XGBoost with 50:50 split to compare performance. We concluded that 70:30 split gives better results.

```{r}
#XG Boost best model with 50-50 split. commenting out while knitting because we are going ahead with 70:30 split.
lcdfSplit<-initial_split(lcdf, prop=0.5)
lcdfTrn0.5 <-training(lcdfSplit)
lcdfTst0.5 <-testing(lcdfSplit)

train_x = data.matrix(lcdfTrn0.5[, -55])
train_y = lcdfTrn0.5[,55]

test_x = data.matrix(lcdfTst0.5[, -55])
test_y = lcdfTst0.5[, 55]

xgb_train = xgb.DMatrix(data =subset(train_x,select=-c(annRet, actualTerm, loan_status)),label = as.matrix(train_y))
xgb_test = xgb.DMatrix(data = subset(test_x,select=-c(annRet, actualTerm, loan_status)), label = as.matrix(test_y))

xgbc = xgboost(data=xgb_train, max.depth = 5, nrounds = 500)

pred_train = predict(xgbc, xgb_train)
sqrt(mean((pred_train-lcdfTrn0.5$actualReturn)^2))
pred_y = predict(xgbc, xgb_test)
sqrt(mean((pred_y-lcdfTst0.5$actualReturn)^2))

plot((predict(xgbc,xgb_train)), lcdfTrn0.5$actualReturn)
plot((predict(xgbc,xgb_test)), lcdfTst0.5$actualReturn)


```
#Q4 - Taking the lower grade loans and then running the previously built models on them - both for predicting actual returns as well as for predicting loan status.The investors can invest in the top 3 deciles for maximum returns. The average return is more than 8%, which is very good.The top 3 deciles contain 3351 loans, out of which 187 are Charged Off and 3164 are Fully Paid.
```{r}

#lower grade loans analysis
lcdf_2 <- subset(lcdf,grade=="C" | grade=="D" | grade=="E" | grade=="F" | grade=="G") 
lcdf_2$loan_status <- factor(lcdf_2$loan_status, levels=c("Fully Paid", "Charged Off"))
#excluding Grade A and Grade B loans

#splitting the data into training and testing dataset

set.seed(1234)
lcdfSplit<-initial_split(lcdf_2, prop=0.7)
lcdfTrn<-training(lcdfSplit)
lcdfTst<-testing(lcdfSplit)

#under sampling
us_lcdfTrn<-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn), na.action= na.pass, method="under", p=0.5)$data
us_lcdfTrn %>% group_by(loan_status) %>% count()
#over sampling
os_lcdfTrn<-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn), na.action= na.pass, method="over", p=0.5)$data
os_lcdfTrn %>% group_by(loan_status) %>% count()
#Both (Under and Over sampling)
bs_lcdfTrn<-ovun.sample(loan_status~., data = as.data.frame(lcdfTrn), na.action= na.pass, method="both", p=0.5)$data
bs_lcdfTrn %>% group_by(loan_status) %>% count()

```
```{r}
#Visualizing data after removing Grade A and Grade B loans
lcdf_grade <- subset(lcdf_2, grade=="C" | grade=="D" | grade=="E" | grade=="F" | grade=="G")
table(lcdf_grade$grade,lcdf_grade$loan_status)
#Bar Graph
ggplot(lcdf_grade, aes(x = grade)) + geom_bar(width = 0.5) + xlab("Grade") + ylab("Total Count")

```
#Q4-We have developed ranger model for loan status for lower grade loans. It has the best accuracy among all the models.
```{r}
#Ranger for loan status - For Q4
library(ranger)
rgModel2<-ranger(as.factor(loan_status)~.,data=subset(lcdfTrn, select=-c(annRet,actualTerm, actualReturn, total_pymnt)),num.trees=200,importance='permutation',probability = TRUE)
#AUC on train set
rgPredictions <- predict(rgModel2, lcdfTrn)$predictions
scoreRG <- rgPredictions[, "Fully Paid"]
predRG <- prediction(scoreRG, lcdfTrn$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerfRG <- performance(predRG, "tpr", "fpr")
plot(aucPerfRG)
abline(a=0, b=1)

aucPerf_RG=performance(predRG, "auc")
aucPerf_RG@y.values
#AUC On test set

rgPredictions <- predict(rgModel2, lcdfTst)$predictions
scoreRG <- rgPredictions[, "Fully Paid"]
predRG <- prediction(scoreRG, lcdfTst$loan_status, label.ordering = c("Charged Off", "Fully Paid"))
aucPerfRG <- performance(predRG, "tpr", "fpr")
plot(aucPerfRG)
abline(a=0, b=1)

aucPerf_RG=performance(predRG, "auc")
aucPerf_RG@y.values

#decile on test set

lg_scoreTstRF <- lcdfTst %>% select(grade, loan_status, actualReturn, actualTerm, int_rate) %>%mutate(scoreRG)
lg_scoreTstRF <- lg_scoreTstRF %>% mutate(tile=ntile(-scoreRG, 10))
v<-lg_scoreTstRF %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(scoreRG),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
view(v)

```

```{r}
#XGBoost best model from part 1b for loan status 
lcdf<-subset(lcdf,select =-c(annRet,actualTerm,actualReturn,total_pymnt))
fdum<-dummyVars(~.,data=lcdf %>% select(-loan_status)) #do not include loan_status for this
dxlcdf <- predict(fdum, lcdf)
# for loan_status, check levels and convert to dummy vars and keep the class label of interest
#levels(lcdf$loan_status)
dylcdf <- class2ind(as.factor(lcdf$loan_status), drop2nd = FALSE)
# and then decide which one to keep
fplcdf <- dylcdf [ , 1] # or, 
colcdf <- dylcdf [ , 2]
#Training, test subsets
TRNFRACTION = 0.7
#Doing a 70-30 split between training and test subsets
nr<-nrow(lcdf)

trnIndex<- sample(1:nr, size = round(TRNFRACTION * nr), replace=FALSE)
lcdfTrn <- lcdf[trnIndex, ]
lcdfTst <- lcdf[-trnIndex, ]
dxlcdfTrn <- dxlcdf[trnIndex,]
colcdfTrn <- colcdf[trnIndex]
dxlcdfTst <- dxlcdf[-trnIndex,]
colcdfTst <- colcdf[-trnIndex]
dxTrn <- xgb.DMatrix(dxlcdfTrn,label=colcdfTrn)
dxTst <- xgb.DMatrix(dxlcdfTst,label=colcdfTst)
xgbWatchlist <- list(train = dxTrn, eval = dxTst)
#we can watch the progress of learning thru performance on these datasets
#list of parameters for the xgboost model development functions
xgbParam <- list (
max_depth = 5, eta = 0.01,
objective = "binary:logistic",
eval_metric="error", eval_metric = "auc")
#can specify which evaluation metrics we want to watch
xgb_lsM1 <- xgb.train( xgbParam, dxTrn, nrounds = 500,
xgbWatchlist, early_stopping_rounds = 10 )
xgb_lsM1$best_iteration
xpredTrg<-predict(xgb_lsM1, dxTrn)
head(xpredTrg) 

xpredTrn<-predict(xgb_lsM1, dxTrn)
xpredTrn1<-ifelse (xpredTrn>0.5,1,0)
pred_xgb_lsM1=prediction(xpredTrn,lcdfTrn$loan_status,label.ordering = c("Fully Paid", "Charged Off"))
yTrn<-factor(if_else(lcdfTrn$loan_status=="Fully Paid", '1', '0') )
confusionMatrix(as.factor(xpredTrn1),yTrn)

xpredTst<-predict(xgb_lsM1, dxTst)
xpredTst1<-ifelse (xpredTst>0.5,1,0)
pred_xgb_lsM1=prediction(xpredTst,lcdfTst$loan_status,label.ordering = c("Fully Paid", "Charged Off"))
yTst<-factor(if_else(lcdfTst$loan_status=="Fully Paid", '1', '0') )
confusionMatrix(as.factor(xpredTst1),yTst)


scoreTst_xgb_ls <- lcdfTst %>% select(grade, loan_status, int_rate) %>% mutate(score=xpredTst)
scoreTst_xgb_ls <- scoreTst_xgb_ls %>% mutate(tile=ntile(-score, 10))
c<-scoreTst_xgb_ls %>% group_by(tile) %>% summarise(count=n(), avgSc=mean(score), numDefaults=sum(loan_status=="Charged Off"),totA=sum(grade=="A"),
totB=sum(grade=="B" ), totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F"))
view(c)
#Combining top d decile scores from the actual returns model based on the loan status model scores
d=1
pRetSc <- predRet_Tst %>%rowwise() %>% mutate(poScore=list(scoreTst_xgb_ls$score))
pRet_d <- pRetSc %>% filter(tile<=d)
pRet_d<- pRet_d %>% mutate(tile2=list(ntile(-poScore, 20)))
d<-pRet_d %>% group_by(tile2) %>% summarise(count=n(), avgPredRet=mean(pred_y),
numDefaults=sum(loan_status=="Charged Off"), avgActRet=mean(actualReturn), minRet=min(actualReturn),
maxRet=max(actualReturn), avgTer=mean(actualTerm), totA=sum(grade=="A"), totB=sum(grade=="B" ),
totC=sum(grade=="C"), totD=sum(grade=="D"), totE=sum(grade=="E"), totF=sum(grade=="F") )
view(d)
```


```{r}
#Visualizing data after removing Grade A and Grade B loans
lcdf_grade <- subset(lcdfTst, grade=="C" | grade=="D" | grade=="E" | grade=="F" | grade=="G")
table(lcdf_grade$grade,lcdf_grade$loan_status)
#Bar Graph
ggplot(lcdfTst, aes(x = grade)) + geom_bar(width = 0.5) + xlab("Grade") + ylab("Total Count")
```

